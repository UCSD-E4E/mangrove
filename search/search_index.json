{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the E4E Mangrove Monitoring Documentation Hub! Github For all code references, please go to the Github repositories below General Tools and Documentation: https://github.com/UCSD-E4E/mangrove Machine Learning Development: https://github.com/UCSD-E4E/ml-mangrove Image Classification Tool: https://github.com/UCSD-E4E/web-mangrove Image Labeling Tool: https://github.com/UCSD-E4E/labeling-mangrove Biomass Estimation: https://github.com/UCSD-E4E/biomass-mangrove Current Team Dillon Hicks Kathy Qi Arden Ma Technical Lead Biomass UNet Segmentation /CNN Matthew Ma Ashlesha Vaidya David Forman - REU UNet Segmentation Semi-Supervised Segmentation Labeling Tool Nicole Meister - REU Samuel Cole - REU Thuan Do - HS Image Classification Tool UNet Segmentation PI's and Collaborators/Mentors E4E (JSOE) Ryan Kastner Curt Schurgers Eric Lo Aburto Lab (SIO) Octavio Aburto Astrid Hsu John Dorian","title":"Home"},{"location":"#welcome-to-the-e4e-mangrove-monitoring-documentation-hub","text":"","title":"Welcome to the E4E Mangrove Monitoring Documentation Hub!"},{"location":"#github","text":"For all code references, please go to the Github repositories below General Tools and Documentation: https://github.com/UCSD-E4E/mangrove Machine Learning Development: https://github.com/UCSD-E4E/ml-mangrove Image Classification Tool: https://github.com/UCSD-E4E/web-mangrove Image Labeling Tool: https://github.com/UCSD-E4E/labeling-mangrove Biomass Estimation: https://github.com/UCSD-E4E/biomass-mangrove","title":"Github"},{"location":"#current-team","text":"Dillon Hicks Kathy Qi Arden Ma Technical Lead Biomass UNet Segmentation /CNN Matthew Ma Ashlesha Vaidya David Forman - REU UNet Segmentation Semi-Supervised Segmentation Labeling Tool Nicole Meister - REU Samuel Cole - REU Thuan Do - HS Image Classification Tool UNet Segmentation","title":"Current Team"},{"location":"#pis-and-collaboratorsmentors","text":"E4E (JSOE) Ryan Kastner Curt Schurgers Eric Lo Aburto Lab (SIO) Octavio Aburto Astrid Hsu John Dorian","title":"PI's and Collaborators/Mentors"},{"location":"About/","text":"What are mangroves? Mangroves are a very valuable and understudied plant species. They provide $100,000 per hectare per year in services that are critical to the overall health of coastal ecosystems. Mangroves act as fishery habitats, they sequester carbon, filter runoff, and protect coastlines from hurricanes, as they lie in coastal or estuarial regions, oftentimes some of the most vulnerable areas to environmental changes. What is the Mangrove Monitoring Project? The Mangrove Monitoring project is a collaboration between Engineers for Exploration at UC San Diego and the Aburto Lab at the Scripps Institute of Oceanography (SIO) at UC San Diego to better track, understand, and track these important types of trees. Both labs focus on mangroves in Baja California, Sur , where we work with local leaders on the conservation of mangroves in these areas. While the Aburto Lab mainly focuses on policy and environmental studies of mangroves, at Engineers for Exploration studies how we can apply Remote Sensing and Machine Learning to monitor these mangroves with mangrove detection and quantification. We use state of the art methods including high resolution drone imagery and deep learning to empower scientists at the Aburto Lab and our collaborators in Mexico to help protect these ecosystems. What is this website? This website is the location where the Mangrove Monitoring Project stores documentation and information related to our Machine Learning Development, Tools, and other solutions we develop. If you want to view our code directly, please visit our github repositories for our various projects below: General Tools and Documentation: https://github.com/UCSD-E4E/mangrove Machine Learning Development: https://github.com/UCSD-E4E/ml-mangrove Image Classification Tool: https://github.com/UCSD-E4E/web-mangrove Image Labeling Tool: https://github.com/UCSD-E4E/labeling-mangrove Biomass Estimation: https://github.com/UCSD-E4E/biomass-mangrove Author Email Dillon Hicks sdhicks@ucsd.edu","title":"About"},{"location":"About/#what-are-mangroves","text":"Mangroves are a very valuable and understudied plant species. They provide $100,000 per hectare per year in services that are critical to the overall health of coastal ecosystems. Mangroves act as fishery habitats, they sequester carbon, filter runoff, and protect coastlines from hurricanes, as they lie in coastal or estuarial regions, oftentimes some of the most vulnerable areas to environmental changes.","title":"What are mangroves?"},{"location":"About/#what-is-the-mangrove-monitoring-project","text":"The Mangrove Monitoring project is a collaboration between Engineers for Exploration at UC San Diego and the Aburto Lab at the Scripps Institute of Oceanography (SIO) at UC San Diego to better track, understand, and track these important types of trees. Both labs focus on mangroves in Baja California, Sur , where we work with local leaders on the conservation of mangroves in these areas. While the Aburto Lab mainly focuses on policy and environmental studies of mangroves, at Engineers for Exploration studies how we can apply Remote Sensing and Machine Learning to monitor these mangroves with mangrove detection and quantification. We use state of the art methods including high resolution drone imagery and deep learning to empower scientists at the Aburto Lab and our collaborators in Mexico to help protect these ecosystems.","title":"What is the Mangrove Monitoring Project?"},{"location":"About/#what-is-this-website","text":"This website is the location where the Mangrove Monitoring Project stores documentation and information related to our Machine Learning Development, Tools, and other solutions we develop. If you want to view our code directly, please visit our github repositories for our various projects below: General Tools and Documentation: https://github.com/UCSD-E4E/mangrove Machine Learning Development: https://github.com/UCSD-E4E/ml-mangrove Image Classification Tool: https://github.com/UCSD-E4E/web-mangrove Image Labeling Tool: https://github.com/UCSD-E4E/labeling-mangrove Biomass Estimation: https://github.com/UCSD-E4E/biomass-mangrove Author Email Dillon Hicks sdhicks@ucsd.edu","title":"What is this website?"},{"location":"Azure%20Slackbot/","text":"Mangrove Azure Updates Mangrove Azure Updates is a slack app developed to make it easier to manage VMs used for data processing and to recieved status updates on those VMs. Turning on and off VMs You can turn of VMs using the commands given below. You can type any of the below commands to turn on and off a specific VM in any channel. Note: After you type in the above commands, wait at least a minute before trying to log into the VM, as it needs time to start up! If the request to start the VM is successful, you should get a message that is visible only to you, with the specific job id of the VM startup job given to Azure. Below is an example message of one that you should recieve upon a successful job request. Autoshutdown Each VM is set to shut down every midnight (12:00 AM PST). If you are doing overnight processing, make sure to go to the #azure channel in order to see updates on automatic shutdowns. Below is an example image for a VM that is left on. This automatic message will be posted 30 minutes before shutdown, (~11:30 PM PST) , so make sure to stay online to ensure that you can see this message. You can either skip the automatic shutdown, with the VM staying on until the next automatic shutdown. If you just need time to save your work and shut down, you can also delay the automatic shutdown by 1 or two hours by clicking on the links in the message sent by @Mangrove Azure Updates. Author Email Dillon Hicks sdhicks@ucsd.edu","title":"Azure Slack Bot"},{"location":"Azure%20Slackbot/#mangrove-azure-updates","text":"Mangrove Azure Updates is a slack app developed to make it easier to manage VMs used for data processing and to recieved status updates on those VMs.","title":"Mangrove Azure Updates"},{"location":"Azure%20Slackbot/#turning-on-and-off-vms","text":"You can turn of VMs using the commands given below. You can type any of the below commands to turn on and off a specific VM in any channel. Note: After you type in the above commands, wait at least a minute before trying to log into the VM, as it needs time to start up! If the request to start the VM is successful, you should get a message that is visible only to you, with the specific job id of the VM startup job given to Azure. Below is an example message of one that you should recieve upon a successful job request.","title":"Turning on and off VMs"},{"location":"Azure%20Slackbot/#autoshutdown","text":"Each VM is set to shut down every midnight (12:00 AM PST). If you are doing overnight processing, make sure to go to the #azure channel in order to see updates on automatic shutdowns. Below is an example image for a VM that is left on. This automatic message will be posted 30 minutes before shutdown, (~11:30 PM PST) , so make sure to stay online to ensure that you can see this message. You can either skip the automatic shutdown, with the VM staying on until the next automatic shutdown. If you just need time to save your work and shut down, you can also delay the automatic shutdown by 1 or two hours by clicking on the links in the message sent by @Mangrove Azure Updates. Author Email Dillon Hicks sdhicks@ucsd.edu","title":"Autoshutdown"},{"location":"CNN/","text":"CNN Tile Based Classification Tensorflow 2.0 Notebooks Upgrades to Tensorflow 2.0 brings much more optimization compared to Tensorflow 1.0 and many more models, Seeing up to 10x increases in classification speeds, plus the code is much easier to read and know what is going on! View the below notebooks to get an intro into the code Retrain (TF2 Notebook) Autoclass (TF2 Notebook)","title":"CNN"},{"location":"CNN/#cnn-tile-based-classification","text":"","title":"CNN Tile Based Classification"},{"location":"CNN/#tensorflow-20-notebooks","text":"Upgrades to Tensorflow 2.0 brings much more optimization compared to Tensorflow 1.0 and many more models, Seeing up to 10x increases in classification speeds, plus the code is much easier to read and know what is going on! View the below notebooks to get an intro into the code","title":"Tensorflow 2.0 Notebooks"},{"location":"CNN/#retrain-tf2-notebook","text":"","title":"Retrain (TF2 Notebook)"},{"location":"CNN/#autoclass-tf2-notebook","text":"","title":"Autoclass (TF2 Notebook)"},{"location":"GIS%20Utils/","text":"Introduction GIS Utils is a python package aimed to improve on many of the inabilities of GDAL Python scripts to be faster, properly multithreaded, and much easier to use with a ML workflow than GDAL on its own. GIS Utils provides a few high level abstractions of GIS workflows aimed to be used for ML workflows, such as tilizing of images, raster to image conversions, and a few other tools specific to our workflow in particular. Requirements In order to use GIS Utils, the below python libraries must be installed: rasterio fiona geopandas gdal We reccomending using Google Colab or an Anaconda Environment as this package also requires many of the packages preincluded in those environments: tqdm numpy pandas For your convenience, we have a series of pip and apt-get commands that you can use below in order to download all of the prerequisite packages for GIS Utils. !apt-get update !apt-get install libgdal-dev -y !apt-get install python-gdal -y !apt-get install python-numpy python-scipy -y !pip install rasterio !pip install fiona !pip install geopandas Once the previous libraries have been installed, you can simply use pip to install GIS Utils to your python environment. pip install -i https://test.pypi.org/simple/ gis-utils-pkg-dillhicks==0.0.2 General Tools load_image() load_image is intended as a quick wrapper to of some rasterio functions to directly get the generator of the image and some of the metainformation of the original image. This function should typically be used in order to Inputs: file - Filelocation of input raster Outputs: img - Image generator from the specified input raster meta - Meta information from the specified input raster get_area() get_area simply gets the area from an input shapefile with the specified CRS from a geopandas dataframe of an input shapefile. Inputs: gpd_df - Filelocation of input raster crs - Projection for which to find the area - note the resulting area can differ greatly between different types of projections, so try to use the same projection in your further calculations. Defaults to EPSG 3857 ( 'epsg:3857' ). Outputs: The area of the polygon(s) in m^2. In order to convert this to km^2, divide this number by 10**6. Retiling Rasters retile() Retile is aimed to be a faster, easier to use version of gdal_retile.py , being able to be used in the form of a python function, and easily transferred to be used in an application or with argparse. It has the ability to output both a numpy array of the original raster, and the ability to save the resulting tiles. Retile is multithreaded, meaning it is much faster than it's older gdal sibling, which unfortunately only runs on 1 thread. Just to give a comparison, this implementation is quicker than gdal_retile.py , especially when you don't save output files and have more threads to access! Type Time gdal_retile.py 13 sec retile() (files = True) 12.5 sec retile() (files = False) 8.25 sec Inputs: img - Image generator from the specified input raster - from load_image meta - Meta information from the specified input raster - from load_image out_path - Output path for image tiles, note that you need to create this folder - defaults to 'images/' files - Whether to output image tiles to the specified out_path - defaults to False width - Width of output tiles in pixels - defaults to 256 height - Height of output tiles in pixels - defaults to 256 Outputs: results - List containing numpy array tiles Note: The tiles outputted have the standard rasterio shape with (bands, rows, columns) , meanwhile many image processing tools such as scikit-image and Pillow use an image shape of (columns,bands,rows) . You can use reshape_as_raster(array) and reshape_as_image(array) to convert to rasterio format and image processing format, respectively. from rasterio.plot import reshape_as_raster, reshape_as_image Example Usage: file = \"lap_2018-07_site05_120m_RGB_cc.tif\" img, meta = load_image(file) results = generate_tiles(img,meta,files=False) tile = reshape_as_image(results[0]) get_tiles() Get tiles is a function to generate the bounds of the image tiles generated in retile . Inputs: ds - Image generator from the specified input raster - from load_image width - Width of output tiles in pixels - defaults to 256 height - Height of output tiles in pixels - defaults to 256 Outputs: out_window, out_transform - A tuple of lists, with each list containing each tiles respective window and transform Example Usage: window, transform = get_tiles(img, width, height) tile = img.read(window=window) Polygonizing Rasters polygonize() Polygonize is intended to be a much faster implementation of gdal_polygonize.py . I'm not going to bring out a chart like I did with retile , but expect 30x increases in processing time compared to gdal_polygonize.py :). Inputs: img : Image generator from the specified input raster - from load_image out_file : Output filename of shapefile to write band : Band in which to make polygons from - defaults to 4 (Alpha layer) Outputs: geopandas_df : Geopandas dataframe containing the geometries from the input raster band Example Usage: file = \"/content/downsampled_m_psc_2018-05_site09_120m_RGB.tif\" img, meta = load_image(file) df = polygonize(img, out_file=\"/content/test.shp\", band=4) Fixing Polygonized Rasters: When generating polygons from the alpha layer, our scripts will generate polygons for all pixel values in the original raster (ex. will make polygons for 0 and 255 alpha values), so the functions below are aimed to fix these and only generate polygons for the specified class of polygons. fix_shp() This is used for the above \"fixing\" of polygons created from polygonize() as explained above. Inputs: shp : geopandas dataframe of the shapefile outputted from polygonize() filename : of input shapefile from polygonize() Outputs: shp : geopandas dataframe of fixed polygons fix_gdalshp() Similarly, this is used for fixing the polygons when generated from gdal_polygonize.py Inputs: shp : geopandas dataframe of the shapefile outputted from gdal_polygonize.py filename : of input shapefile from gdal_polygonize.py Outputs: shp : geopandas dataframe of fixed polygons Downsampling Rasters downsample_raster() As the name intends, this is for downsampling rasters. This has been used previously in order to generate previews for all of our rasters in the drive that are geolocated and can easily be used for testing. Inputs: img - Image generator from the specified input raster - from load_image downscale_factor - How much to downsample (or upsample) your image. An appropriate input would be 1/25 , 1/5 , 10 , etc. out_file - Output filename of downsampled raster to write Outputs: resampled - Output numpy array of the resampled raster transform - Transform of the resampled raster Demo Notebook Author Email Dillon Hicks sdhicks@ucsd.edu","title":"GIS Utils"},{"location":"GIS%20Utils/#introduction","text":"GIS Utils is a python package aimed to improve on many of the inabilities of GDAL Python scripts to be faster, properly multithreaded, and much easier to use with a ML workflow than GDAL on its own. GIS Utils provides a few high level abstractions of GIS workflows aimed to be used for ML workflows, such as tilizing of images, raster to image conversions, and a few other tools specific to our workflow in particular.","title":"Introduction"},{"location":"GIS%20Utils/#requirements","text":"In order to use GIS Utils, the below python libraries must be installed: rasterio fiona geopandas gdal We reccomending using Google Colab or an Anaconda Environment as this package also requires many of the packages preincluded in those environments: tqdm numpy pandas For your convenience, we have a series of pip and apt-get commands that you can use below in order to download all of the prerequisite packages for GIS Utils. !apt-get update !apt-get install libgdal-dev -y !apt-get install python-gdal -y !apt-get install python-numpy python-scipy -y !pip install rasterio !pip install fiona !pip install geopandas Once the previous libraries have been installed, you can simply use pip to install GIS Utils to your python environment. pip install -i https://test.pypi.org/simple/ gis-utils-pkg-dillhicks==0.0.2","title":"Requirements"},{"location":"GIS%20Utils/#general-tools","text":"","title":"General Tools"},{"location":"GIS%20Utils/#load_image","text":"load_image is intended as a quick wrapper to of some rasterio functions to directly get the generator of the image and some of the metainformation of the original image. This function should typically be used in order to Inputs: file - Filelocation of input raster Outputs: img - Image generator from the specified input raster meta - Meta information from the specified input raster","title":"load_image()"},{"location":"GIS%20Utils/#get_area","text":"get_area simply gets the area from an input shapefile with the specified CRS from a geopandas dataframe of an input shapefile. Inputs: gpd_df - Filelocation of input raster crs - Projection for which to find the area - note the resulting area can differ greatly between different types of projections, so try to use the same projection in your further calculations. Defaults to EPSG 3857 ( 'epsg:3857' ). Outputs: The area of the polygon(s) in m^2. In order to convert this to km^2, divide this number by 10**6.","title":"get_area()"},{"location":"GIS%20Utils/#retiling-rasters","text":"","title":"Retiling Rasters"},{"location":"GIS%20Utils/#retile","text":"Retile is aimed to be a faster, easier to use version of gdal_retile.py , being able to be used in the form of a python function, and easily transferred to be used in an application or with argparse. It has the ability to output both a numpy array of the original raster, and the ability to save the resulting tiles. Retile is multithreaded, meaning it is much faster than it's older gdal sibling, which unfortunately only runs on 1 thread. Just to give a comparison, this implementation is quicker than gdal_retile.py , especially when you don't save output files and have more threads to access! Type Time gdal_retile.py 13 sec retile() (files = True) 12.5 sec retile() (files = False) 8.25 sec Inputs: img - Image generator from the specified input raster - from load_image meta - Meta information from the specified input raster - from load_image out_path - Output path for image tiles, note that you need to create this folder - defaults to 'images/' files - Whether to output image tiles to the specified out_path - defaults to False width - Width of output tiles in pixels - defaults to 256 height - Height of output tiles in pixels - defaults to 256 Outputs: results - List containing numpy array tiles Note: The tiles outputted have the standard rasterio shape with (bands, rows, columns) , meanwhile many image processing tools such as scikit-image and Pillow use an image shape of (columns,bands,rows) . You can use reshape_as_raster(array) and reshape_as_image(array) to convert to rasterio format and image processing format, respectively. from rasterio.plot import reshape_as_raster, reshape_as_image Example Usage: file = \"lap_2018-07_site05_120m_RGB_cc.tif\" img, meta = load_image(file) results = generate_tiles(img,meta,files=False) tile = reshape_as_image(results[0])","title":"retile()"},{"location":"GIS%20Utils/#get_tiles","text":"Get tiles is a function to generate the bounds of the image tiles generated in retile . Inputs: ds - Image generator from the specified input raster - from load_image width - Width of output tiles in pixels - defaults to 256 height - Height of output tiles in pixels - defaults to 256 Outputs: out_window, out_transform - A tuple of lists, with each list containing each tiles respective window and transform Example Usage: window, transform = get_tiles(img, width, height) tile = img.read(window=window)","title":"get_tiles()"},{"location":"GIS%20Utils/#polygonizing-rasters","text":"","title":"Polygonizing Rasters"},{"location":"GIS%20Utils/#polygonize","text":"Polygonize is intended to be a much faster implementation of gdal_polygonize.py . I'm not going to bring out a chart like I did with retile , but expect 30x increases in processing time compared to gdal_polygonize.py :). Inputs: img : Image generator from the specified input raster - from load_image out_file : Output filename of shapefile to write band : Band in which to make polygons from - defaults to 4 (Alpha layer) Outputs: geopandas_df : Geopandas dataframe containing the geometries from the input raster band Example Usage: file = \"/content/downsampled_m_psc_2018-05_site09_120m_RGB.tif\" img, meta = load_image(file) df = polygonize(img, out_file=\"/content/test.shp\", band=4)","title":"polygonize()"},{"location":"GIS%20Utils/#fixing-polygonized-rasters","text":"When generating polygons from the alpha layer, our scripts will generate polygons for all pixel values in the original raster (ex. will make polygons for 0 and 255 alpha values), so the functions below are aimed to fix these and only generate polygons for the specified class of polygons.","title":"Fixing Polygonized Rasters:"},{"location":"GIS%20Utils/#fix_shp","text":"This is used for the above \"fixing\" of polygons created from polygonize() as explained above. Inputs: shp : geopandas dataframe of the shapefile outputted from polygonize() filename : of input shapefile from polygonize() Outputs: shp : geopandas dataframe of fixed polygons","title":"fix_shp()"},{"location":"GIS%20Utils/#fix_gdalshp","text":"Similarly, this is used for fixing the polygons when generated from gdal_polygonize.py Inputs: shp : geopandas dataframe of the shapefile outputted from gdal_polygonize.py filename : of input shapefile from gdal_polygonize.py Outputs: shp : geopandas dataframe of fixed polygons","title":"fix_gdalshp()"},{"location":"GIS%20Utils/#downsampling-rasters","text":"","title":"Downsampling Rasters"},{"location":"GIS%20Utils/#downsample_raster","text":"As the name intends, this is for downsampling rasters. This has been used previously in order to generate previews for all of our rasters in the drive that are geolocated and can easily be used for testing. Inputs: img - Image generator from the specified input raster - from load_image downscale_factor - How much to downsample (or upsample) your image. An appropriate input would be 1/25 , 1/5 , 10 , etc. out_file - Output filename of downsampled raster to write Outputs: resampled - Output numpy array of the resampled raster transform - Transform of the resampled raster","title":"downsample_raster()"},{"location":"GIS%20Utils/#demo-notebook","text":"Author Email Dillon Hicks sdhicks@ucsd.edu","title":"Demo Notebook"},{"location":"Image%20Classification%20Tool/","text":"","title":"Image Classification Tool"},{"location":"Labeling%20Tool/","text":"Welcome to Magic Label Paint, a user interface for ML-assisted labeling. beta internal mangrove release Downloading the application Go to the github page and find the download button (lower right). Running the .JAR file MLPaint is a Java programming language .jar desktop application. To run it, you will need to have Java installed on your computer. Even if you have Java already installed, you may need to Google how to update it to Java 11. Windows: All that should be covered in this video for Windows. Mac: 1) How to download Java You will need at least Java SE 11. 2) How to run a .jar file This video explains how to use Mac Terminal to navigate to your file: 1) Use \"ls\" to see your directory names 2) Use \"cd\" to enter a directory. 3) Once you are in the same directory as the .jar file, run \"java -jar MLPaint.jar\" Tutorial: Loading an image to label Navigate to the image, probably a .tif, that you want to open, and open it! Tutorial: The Labeling Workflow","title":"Labeling Tool"},{"location":"Labeling%20Tool/#welcome-to-magic-label-paint-a-user-interface-for-ml-assisted-labeling","text":"beta internal mangrove release","title":"Welcome to Magic Label Paint, a user interface for ML-assisted labeling."},{"location":"Labeling%20Tool/#downloading-the-application","text":"Go to the github page and find the download button (lower right).","title":"Downloading the application"},{"location":"Labeling%20Tool/#running-the-jar-file","text":"MLPaint is a Java programming language .jar desktop application. To run it, you will need to have Java installed on your computer. Even if you have Java already installed, you may need to Google how to update it to Java 11. Windows: All that should be covered in this video for Windows. Mac: 1) How to download Java You will need at least Java SE 11. 2) How to run a .jar file This video explains how to use Mac Terminal to navigate to your file: 1) Use \"ls\" to see your directory names 2) Use \"cd\" to enter a directory. 3) Once you are in the same directory as the .jar file, run \"java -jar MLPaint.jar\"","title":"Running the .JAR file"},{"location":"Labeling%20Tool/#tutorial-loading-an-image-to-label","text":"Navigate to the image, probably a .tif, that you want to open, and open it!","title":"Tutorial: Loading an image to label"},{"location":"Labeling%20Tool/#tutorial-the-labeling-workflow","text":"","title":"Tutorial: The Labeling Workflow"},{"location":"Misc/","text":"","title":"Misc"},{"location":"Papers/","text":"CNN Paper - IROS 2020 (Pending) 2019 REU Final Report","title":"Papers"},{"location":"Papers/#cnn-paper-iros-2020-pending","text":"","title":"CNN Paper - IROS 2020 (Pending)"},{"location":"Papers/#2019-reu-final-report","text":"","title":"2019 REU Final Report"},{"location":"Semi-Supervised/","text":"","title":"Semi-Supervised"},{"location":"UNet/","text":"Introduction This UNet uses a convolutional network backbone chosen by the user to label pixels of an input image as either \"mangrove\" or \"non-mangrove\" (Semantic Segmentation) The UNet is a group of four scripts and unet.py For training, testing, and generating predictions one only needs to run unet.py Requirements In order to use unet.py or any of the associated helper scripts: create_seg_dataset.py gen_seg_labels.py raster_mask.py split_vector.py The python libraries below must be installed: keras tensorflow_gpu>=2.2 or tensorflow>=2.2 (this is dependent on your machine/gpu ) segmentation_models Fiona rasterio gdal Note : If you have never used the GDAL libaries before, use the following commands: apt-get install libgdal-dev apt-get install python-gdal We recommend using Google Colab or an Anaconda Environment as this package also requires many of the packages preincluded in those environments: tqdm numpy matplotlib Pillow joblib ml-mangrove/Segmentation/requirements.txt will have a version complete list of the neccesary libaries File Structure In order to properly use the current build of unet.py and have all functions write to the correct directories, follow these rules and use these EXACT directory names: unet.py and 4 helper scripts MUST be in same directory, for this example it will be /Segmentation In the parent directory of /Segmentation , lets call it /ml-mangrove , create a directory /ml-mangrove/dataset In /dataset , create directories /dataset/training or /dataset/testing depending on intended use of unet.py For training, create /training/images for orthomosaics, and /training/vectors for shapefiles For testing create /testing/images for orthomosaics, and /testing/output for output rasters Using the UNet unet.py unet.py takes input orthomosaic(s) and shapefile(s) pairs for training a binary mangrove classifier, and outputs a weight file to be used for testing. When testing this script takes input orthomosaic(s) and a weight file and outputs pieces (tiles) of the original orthomosaic that have been masked with the masks predicted by the UNet. Inputs: width - size of tiles in pixels (used in retiling) input_rasters - filepath(s) to orthomosaic .tif input_vectors (required for training) - filepath(s) to shapefile for orthomosaic .shp (ordering should correspond with input rasters) train : include this flag if training the UNet test : include this flag if testing the UNet weights : filepath to weights file .h5 , write location if training, or to use for testing backbone : name of backbone to use ex: resnet34 or vgg16 Note: shapefile .shp must be in the SAME directory as .shx , .dbf , .prj , .qpj , and .cpg files of the SAME name Training the UNet Example Usage: python3 unet.py --width 256 --input_rasters ../dataset/training/images/ortho1.tif ../dataset/training/images/ortho2.tif --input_vectors ../dataset/training/vectors/shapefile1.shp ../dataset/training/vectors/shapefile2.shp --train --weights ../dataset/training/weights/new_weight.h5 --backbone vgg16 Testing the UNet Example Usage: python3 unet.py --width 256 --input_rasters ../dataset/testing/images/ortho1.tif ../dataset/testing/images/ortho2.tif --test --weights ../dataset/testing/weights/weight_vgg16.h5 --backbone vgg16 Helper Scripts The following scripts are called upon either directly or indirectly by unet.py create_seg_dataset.py create_seg_dataset.py uses the provided map files to place pairs of images and annotations in their proper directories Inputs: map_files - space seperated txt file(s) with image path data dir_name - directory above /images and /annotations directories (training or testing) include_tif - boolean that indicates .tif files are to be moved into /images as well Example Usage: python3 create_seg_dataset.py --map_files ../dataset/Site_1/map.txt ../dataset/Site_4/map.txt gen_seg_labels.py gen_seg_labels.py creates /images and /labels directories, calls gdal_retile.py on both the raster_file and mask_file , and creates map file that pairs images and labels (created during retiling). Inputs: width - size of tiles in pixels (used in retiling) input_raster - filepath to orthomosaic (.tif) input_vector - filepath to shapefile for orthomosaic (.shp) input_mask - filepath to mask file if provided (otherwise raster_mask.py is called) out_dir - directory above /images and /labels directories and map file convert - boolean that indicates (retiled) labels/images are converted from .tif to .jpg destructive - boolean that indicates .tif files are deleted after conversion to .jpg Note: shapefile .shp must be in the SAME directory as .shx , .dbf , .prj , .qpj , and .cpg files of the SAME name Example Usage: python3 gen_seg_labels.py --width 256 --input_raster test_data/test.tif --input_mask test_data/masks/mask_binary.tif -c -d Or with a .shp file: python3 gen_seg_labels.py --width 256 --input_raster test_data/test.tif --input_vector test_data/test.shp raster_mask.py raster_mask.py (if vectors not split) calls split_vector.py to seperate input_vector into m.shp and nm.shp and then creates a binary pixel mask for mangrove v non-mangrove ( mask_binary.tif and mask_binary.png ). Can easily be extended to use multiple .shp files by creating corresponding numpy arrays and combining them Note: this function can bog down machines with insufficent ram (<16gb) rasterio Documentation: Masks Masking by shapefile Inputs: raster_filepath - filepath to orthomosaic .tif vector_filepath - filepath to original shapefile .shp Note: shapefile .shp must be in the SAME directory as .shx , .dbf , .prj , .qpj , and .cpg files of the SAME name Example Usage: python3 raster_mask.py --raster_filepath test_data/test.tif --vector_filepath test_data/test.shp split_vector.py split_vector.py creates /m and /nm directories and splits a shapefile .shp into \"mangrove\" and \"non-mangrove\" shapefiles .shp . Inputs: filepath - filepath to original shapefile .shp to be split. Note: shapefile .shp must be in the SAME directory as .shx , .dbf , .prj , .qpj , and .cpg files of the SAME name Example Usage: python3 split_vector.py test_data/test.shp Author Email Sam Cole scole02@calpoly.edu","title":"UNet"},{"location":"UNet/#introduction","text":"This UNet uses a convolutional network backbone chosen by the user to label pixels of an input image as either \"mangrove\" or \"non-mangrove\" (Semantic Segmentation) The UNet is a group of four scripts and unet.py For training, testing, and generating predictions one only needs to run unet.py","title":"Introduction"},{"location":"UNet/#requirements","text":"In order to use unet.py or any of the associated helper scripts: create_seg_dataset.py gen_seg_labels.py raster_mask.py split_vector.py The python libraries below must be installed: keras tensorflow_gpu>=2.2 or tensorflow>=2.2 (this is dependent on your machine/gpu ) segmentation_models Fiona rasterio gdal Note : If you have never used the GDAL libaries before, use the following commands: apt-get install libgdal-dev apt-get install python-gdal We recommend using Google Colab or an Anaconda Environment as this package also requires many of the packages preincluded in those environments: tqdm numpy matplotlib Pillow joblib ml-mangrove/Segmentation/requirements.txt will have a version complete list of the neccesary libaries","title":"Requirements"},{"location":"UNet/#file-structure","text":"In order to properly use the current build of unet.py and have all functions write to the correct directories, follow these rules and use these EXACT directory names: unet.py and 4 helper scripts MUST be in same directory, for this example it will be /Segmentation In the parent directory of /Segmentation , lets call it /ml-mangrove , create a directory /ml-mangrove/dataset In /dataset , create directories /dataset/training or /dataset/testing depending on intended use of unet.py For training, create /training/images for orthomosaics, and /training/vectors for shapefiles For testing create /testing/images for orthomosaics, and /testing/output for output rasters","title":"File Structure"},{"location":"UNet/#using-the-unet","text":"","title":"Using the UNet"},{"location":"UNet/#unetpy","text":"unet.py takes input orthomosaic(s) and shapefile(s) pairs for training a binary mangrove classifier, and outputs a weight file to be used for testing. When testing this script takes input orthomosaic(s) and a weight file and outputs pieces (tiles) of the original orthomosaic that have been masked with the masks predicted by the UNet. Inputs: width - size of tiles in pixels (used in retiling) input_rasters - filepath(s) to orthomosaic .tif input_vectors (required for training) - filepath(s) to shapefile for orthomosaic .shp (ordering should correspond with input rasters) train : include this flag if training the UNet test : include this flag if testing the UNet weights : filepath to weights file .h5 , write location if training, or to use for testing backbone : name of backbone to use ex: resnet34 or vgg16 Note: shapefile .shp must be in the SAME directory as .shx , .dbf , .prj , .qpj , and .cpg files of the SAME name Training the UNet Example Usage: python3 unet.py --width 256 --input_rasters ../dataset/training/images/ortho1.tif ../dataset/training/images/ortho2.tif --input_vectors ../dataset/training/vectors/shapefile1.shp ../dataset/training/vectors/shapefile2.shp --train --weights ../dataset/training/weights/new_weight.h5 --backbone vgg16 Testing the UNet Example Usage: python3 unet.py --width 256 --input_rasters ../dataset/testing/images/ortho1.tif ../dataset/testing/images/ortho2.tif --test --weights ../dataset/testing/weights/weight_vgg16.h5 --backbone vgg16","title":"unet.py"},{"location":"UNet/#helper-scripts","text":"The following scripts are called upon either directly or indirectly by unet.py","title":"Helper Scripts"},{"location":"UNet/#create_seg_datasetpy","text":"create_seg_dataset.py uses the provided map files to place pairs of images and annotations in their proper directories Inputs: map_files - space seperated txt file(s) with image path data dir_name - directory above /images and /annotations directories (training or testing) include_tif - boolean that indicates .tif files are to be moved into /images as well Example Usage: python3 create_seg_dataset.py --map_files ../dataset/Site_1/map.txt ../dataset/Site_4/map.txt","title":"create_seg_dataset.py"},{"location":"UNet/#gen_seg_labelspy","text":"gen_seg_labels.py creates /images and /labels directories, calls gdal_retile.py on both the raster_file and mask_file , and creates map file that pairs images and labels (created during retiling). Inputs: width - size of tiles in pixels (used in retiling) input_raster - filepath to orthomosaic (.tif) input_vector - filepath to shapefile for orthomosaic (.shp) input_mask - filepath to mask file if provided (otherwise raster_mask.py is called) out_dir - directory above /images and /labels directories and map file convert - boolean that indicates (retiled) labels/images are converted from .tif to .jpg destructive - boolean that indicates .tif files are deleted after conversion to .jpg Note: shapefile .shp must be in the SAME directory as .shx , .dbf , .prj , .qpj , and .cpg files of the SAME name Example Usage: python3 gen_seg_labels.py --width 256 --input_raster test_data/test.tif --input_mask test_data/masks/mask_binary.tif -c -d Or with a .shp file: python3 gen_seg_labels.py --width 256 --input_raster test_data/test.tif --input_vector test_data/test.shp","title":"gen_seg_labels.py"},{"location":"UNet/#raster_maskpy","text":"raster_mask.py (if vectors not split) calls split_vector.py to seperate input_vector into m.shp and nm.shp and then creates a binary pixel mask for mangrove v non-mangrove ( mask_binary.tif and mask_binary.png ). Can easily be extended to use multiple .shp files by creating corresponding numpy arrays and combining them Note: this function can bog down machines with insufficent ram (<16gb) rasterio Documentation: Masks Masking by shapefile Inputs: raster_filepath - filepath to orthomosaic .tif vector_filepath - filepath to original shapefile .shp Note: shapefile .shp must be in the SAME directory as .shx , .dbf , .prj , .qpj , and .cpg files of the SAME name Example Usage: python3 raster_mask.py --raster_filepath test_data/test.tif --vector_filepath test_data/test.shp","title":"raster_mask.py"},{"location":"UNet/#split_vectorpy","text":"split_vector.py creates /m and /nm directories and splits a shapefile .shp into \"mangrove\" and \"non-mangrove\" shapefiles .shp . Inputs: filepath - filepath to original shapefile .shp to be split. Note: shapefile .shp must be in the SAME directory as .shx , .dbf , .prj , .qpj , and .cpg files of the SAME name Example Usage: python3 split_vector.py test_data/test.shp Author Email Sam Cole scole02@calpoly.edu","title":"split_vector.py"}]}